{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Field Goals: An Observational Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from matching.cem import CEM\n",
    "from matching.imbalance import imbalance, get_imbalance_params\n",
    "from util.evaluation import odds_ratios, binned_residuals, plot_binned_residuals, to_frame\n",
    "from util.metrics import correlations\n",
    "from util.fg_data import clean, get_data\n",
    "\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from datetime import datetime as dt\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "sns.set_palette('colorblind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean the data\n",
    "cnx = mysql.connector.connect(user='root', password='mOntie20!mysql', host='127.0.0.1', database='nfl')\n",
    "df = get_data(cnx, 'g.seas<=2019', xp=False, base='raw_6_cat')\n",
    "df = clean(df, dropna=False)\n",
    "df = df.drop(['fkicker', 'home_team', 'stadium', 'team', 'XP', 'humid', 'kicks', 'age', 'form'], axis=1)\n",
    "df['year'] = df['year']-df['year'].min()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the variables\n",
    "binary = ['altitude', 'iced', 'turf', 'postseason', 'away_game', 'precipitation']\n",
    "continuous = ['distance', 'year', 'seasons', 'temperature', 'wind', 'pressure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = correlations(df, continuous, binary)\n",
    "df_corr\n",
    "# print(df_corr[abs(df_corr['corr'])>0.3].sort_values('corr').round(2).to_latex())\n",
    "# print(df.loc[:,continuous].corr('spearman').round(2).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set(font_scale=1)\n",
    "# ax = sns.pairplot(df.loc[:,continuous].sample(frac=0.5), diag_kind='hist', plot_kws=dict(s=10, edgecolor=\"b\", linewidth=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding H\n",
    "\n",
    "Find a common values for H, the number of bins for a continuous variable, that will be used to fairly compare the empirical imbalance for matched and unmatched analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "cont_bins = range(1, 10)\n",
    "\n",
    "for h, treatment in tqdm(itertools.product(cont_bins,binary), total=len(binary)*len(cont_bins)):\n",
    "    bins = get_imbalance_params(df.drop([treatment, 'good'], axis=1),\n",
    "                                'l1', continuous, h)\n",
    "    l1 = imbalance(df.drop('good', axis=1).astype(int), treatment, 'l1', bins)\n",
    "    rows.append({'L1':l1, 'treatment':treatment, 'H':h})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb = pd.DataFrame.from_records(rows)\n",
    "imb = imb.loc[imb['L1']<1, :]\n",
    "\n",
    "ax = sns.lineplot(x='H', y='L1', data=imb, hue='treatment', style='treatment', markers=True)\n",
    "ax.set_title('L1 profile of raw data', size=16)\n",
    "ax.set_xlabel('H', size=16)\n",
    "ax.set_ylabel('L1    ', size=16, rotation='horizontal')\n",
    "ax.tick_params(labelsize=12, size=2)\n",
    "plt.savefig('../images/L1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance\n",
    "\n",
    "We first find the multivariate and univariate imbalance when each of the binary variables are considered the treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(val):\n",
    "    # for annotating regression coefficients by significance\n",
    "    if val<0.01:\n",
    "        return '***'\n",
    "    elif val<0.05:\n",
    "        return '**'\n",
    "    elif val<0.1:\n",
    "        return '*'\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = {}\n",
    "imb = {}\n",
    "for t in binary:\n",
    "    cem = CEM(df, t, 'good', continuous, H=4)\n",
    "    multi[t] = cem.preimbalance\n",
    "\n",
    "    ub = cem.univariate_imbalance()\n",
    "    imb[t] = ub['imbalance'].round(3).astype(str)+ub['P>|z|'].apply(pp) \n",
    "\n",
    "df_imb = pd.DataFrame.from_dict(imb, orient='columns')\n",
    "df_imb = df_imb.append(pd.DataFrame(multi, index=['multivariate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_imb.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "We now perform logisitic regression for 4 different model specifications (simple, main effects, interactions, and full).\n",
    "\n",
    "* df_unmatched is all covariate estimates for all models.\n",
    "* results_unmatched is a dict of all statsmodels.Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a collection of the formulas to pass to the sm API.\n",
    "formulas_simple = {t:f'good ~ {t}' for t in df.drop('good', axis=1).columns}\n",
    "formula_main = {'main effects':'good ~ '+ ' + '.join(df.drop('good', axis=1).columns)}\n",
    "formula_interaction = {'interactions':'good ~ '+ ' + '.join(df.drop('good', axis=1).columns) + f'+ iced*pressure + altitude*distance'}\n",
    "formula_full = {'full':'good ~ ' + ' + '.join(df.drop(['good'], axis=1).columns) + f'+ np.log(wind+1) + np.log(seasons) + np.log(distance) + iced*pressure + altitude*distance'}\n",
    "formulas = {**formulas_simple, **formula_main, **formula_interaction, **formula_full}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# perform the regressions\n",
    "df_unmatched = pd.DataFrame(columns=['coefficient', 'P>|z|', 'bse', 'model'])\n",
    "results_unmatched = {}\n",
    "for name, formula in formulas.items():\n",
    "    glm = smf.glm(formula, data=df, family=sm.families.Binomial())\n",
    "    result = glm.fit(method='bfgs', maxiter=10000)\n",
    "    results_unmatched[name] = result\n",
    "    model = name if name not in df.columns else 'simple'\n",
    "    df_unmatched = pd.concat((df_unmatched, pd.DataFrame({'coefficient':result.params, 'P>|z|':result.pvalues, 'bse': result.bse, 'model':model})))\n",
    "\n",
    "df_unmatched.index.rename('covariate', inplace=True)\n",
    "df_unmatched = df_unmatched.reset_index('covariate')\n",
    "results_unmatched = pd.Series(results_unmatched, name='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unmatched.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Presenting Coefficients and Estimated Treatment Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the order of covariates so the table looks pretty\n",
    "order_ = OrderedDict()\n",
    "for cov in df_unmatched['covariate']:\n",
    "    if cov != 'Intercept':\n",
    "        order_[cov] = cov if 'np.' not in cov else cov.split('.')[-1]\n",
    "order_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want a table where the columns are models, so we have to pivot on the the 'model' column and drop the Intercept estimates.\n",
    "df_um = df_unmatched.loc[df_unmatched['covariate']!='Intercept', :]\n",
    "df_um['coefficient'] = df_um['coefficient'].round(3).astype(str) + df_um['P>|z|'].apply(pp)\n",
    "df_um = df_um.loc[:,['covariate', 'coefficient', 'model']]\n",
    "df_um = df_um.pivot('covariate', columns='model', values='coefficient').loc[list(order_.keys()), ['simple', 'main effects', 'interactions', 'full']]\n",
    "print(df_um.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe the table is a little hard to read so we create bar charts of the regression coefficients\n",
    "df_cat = df_unmatched.loc[df_unmatched['covariate']!='Intercept', :]\n",
    "df_cat.head()\n",
    "\n",
    "xlim = (-0.5, 0.5)\n",
    "keys = list(order_.keys())\n",
    "for name, group in df_cat.groupby('model'):\n",
    "    group = group.set_index('covariate')\n",
    "    group['abs'] = group['coefficient']>0\n",
    "    group = group.loc[[i for i in keys if i in group.index], :].reset_index()\n",
    "    \n",
    "    g = sns.barplot(x='coefficient', y='covariate', hue='abs', data=group, palette={True:'lightgreen', False:'r'})\n",
    "    g.get_legend().remove()\n",
    "\n",
    "    for _, row in group.iterrows():\n",
    "        x = row['coefficient']+0.03 if row['coefficient']>0 else row['coefficient']-0.03\n",
    "        msg = pp(row['P>|z|'])\n",
    "        y = keys.index(row['covariate'])+0.2 # i hope this is correct\n",
    "        color = 'black'\n",
    "        if abs(row['coefficient']) > xlim[1]:\n",
    "            msg += f'({round(row.coefficient,2)})'\n",
    "            x = 0.1 if row['coefficient']<xlim[0] else -0.05\n",
    "            y += 0.1\n",
    "            # color = 'white'\n",
    "        g.text(x, y, msg, ha='center', color=color)\n",
    "\n",
    "    s = 's' if name=='simple' else ''\n",
    "    g.set_title(f'Regression coefficients for {name} model{s}')\n",
    "    g.set_yticklabels(order_.values())\n",
    "    g.set_xlabel('')\n",
    "    g.set_ylabel('')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.xlim(*xlim)\n",
    "    plt.savefig(f'../images/unmatched_coef_plots/{name}.png', bbox_inches='tight')\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Treatment Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SATE estimates for each model for each possible treatment\n",
    "from scipy.stats import norm\n",
    "sates = []\n",
    "for t in binary:\n",
    "    df_treated = df.copy()\n",
    "    df_control = df.copy()\n",
    "    df_treated[t] = 1\n",
    "    df_control[t] = 0\n",
    "\n",
    "    for name, result in results_unmatched.items():\n",
    "        if (name in continuous) or (name in binary and name!=t):\n",
    "            continue\n",
    "        # calculate outcomes under treatment or not\n",
    "        treated_outcome = result.predict(df_treated)\n",
    "        control_outcome = result.predict(df_control)\n",
    "        t_mean = treated_outcome.mean()\n",
    "        c_mean = control_outcome.mean()\n",
    "        sate = t_mean - c_mean\n",
    "\n",
    "        # significance test\n",
    "        pooled = (t_mean+c_mean)/2\n",
    "        pooled_se = np.sqrt(2*pooled*(1-pooled)/len(df))\n",
    "        z = sate/pooled_se\n",
    "        p = norm.sf(abs(z))\n",
    "\n",
    "        sates.append({'treatment':t, 'model':name if name not in binary else 'simple', 'SATE':str(round(sate,3))+pp(p)})\n",
    "df_sate = pd.DataFrame.from_records(sates).set_index(['treatment', 'model'])\n",
    "print(df_sate.round(3).to_latex())\n",
    "# df_sate.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conditional treatment effects (heterogeneous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CATE(result, T, X, X_val, cov):\n",
    "    assert 'covariate' in result.columns and 'coefficient' in result.columns, 'Cannot find \"covariate\" or \"coefficient\" columns.'\n",
    "    result = result.loc[[T in r for r in result['covariate']], :].copy()\n",
    "    result['val'] = result['covariate'].str.replace(':', '*').apply(lambda x: eval(x, {T:1, X:X_val, 'np':np}))\n",
    "    result['val*beta'] = result['val']*result['coefficient']\n",
    "    result.set_index('covariate', inplace=True)\n",
    "    cate = result['val*beta'].sum()\n",
    "    variance = {x: cov.loc[x,x] for x in result.index}\n",
    "    covariance = {(x,y): cov.loc[x, y] for x, y in itertools.combinations(result.index, 2)}\n",
    "    variance_terms = sum([v*result.loc[k,'val']**2 for k, v in variance.items()])\n",
    "    covariance_terms = sum([2*result.loc[x,'val']*result.loc[y, 'val']*cv for (x,y), cv in covariance.items()])\n",
    "    se = np.sqrt(variance_terms + covariance_terms)\n",
    "    return cate, se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "pairs = (('iced', 'pressure'), ('altitude', 'distance'))\n",
    "models = ('interactions', 'full')\n",
    "for (T, M), model in itertools.product(pairs, models):\n",
    "    vals = range(df[M].min(), df[M].max()+1)\n",
    "\n",
    "    result = df_unmatched.loc[df_unmatched['model']==model, :]\n",
    "    vc = results_unmatched[model].cov_params()\n",
    "\n",
    "    ATE, SE = zip(*[CATE(result, T, M, d, vc) for d in vals])\n",
    "\n",
    "    fig, axes = plt.subplots(2,1)\n",
    "    sns.distplot(df[M], kde=False, ax=axes[1])\n",
    "    ax = sns.lineplot(x=vals, y=ATE, ax=axes[0])\n",
    "    lb = np.array(ATE) - 1.96*np.array(SE)\n",
    "    ub = np.array(ATE) + 1.96*np.array(SE)\n",
    "    axes[0].fill_between(vals,lb,ub, alpha=0.3)\n",
    "    ax.set_title(f'Marginal effect of {T} with {M}')\n",
    "    axes[1].set_xlabel(M, size=12)\n",
    "    ax.set_ylabel(f'Marginal effect of {T}', size=12)\n",
    "    axes[1].set_ylabel('Count', size=12)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.hlines(0,df[M].min(), df[M].max(), colors='r', alpha=0.5, linestyles='dashed')\n",
    "    plt.savefig(f'../images/unmatched_{T}/{M}_{model}.png')\n",
    "    plt.cla()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = df['pressure'].value_counts().sort_index(ascending=True).round(3).to_frame()\n",
    "pres.index.rename('Level', inplace=True)\n",
    "pres = pres.rename(columns={'pressure':'Count'})\n",
    "print(pres.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ('main effects', 'interactions', 'full')\n",
    "models = formulas.keys()\n",
    "ons = ['pred']+continuous\n",
    "for model, on in itertools.product(models, ons):\n",
    "    resid = binned_residuals(results_unmatched[model], df.drop('good', axis=1), df['good'], bins=None, on=on)\n",
    "    pct = round(resid['inside'].mean()*100,1)\n",
    "    ax = plot_binned_residuals(resid, on=on)\n",
    "    ax.set_title(f'Binned residuals on {on} for {model} model ({pct}% inside)', size=12)\n",
    "    model = '_'.join(model.split())\n",
    "    plt.savefig(f'../images/unmatched_residuals/{model}_{on}.png')\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarsening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_plot(data, var, cuts=3, func=pd.cut, bins=None, **kwargs):\n",
    "    ax = sns.distplot(data[var], kde=False, bins=bins)    \n",
    "    out, bins = func(data[var], cuts, retbins=True, **kwargs)\n",
    "    for bin_ in bins:\n",
    "        plt.axvline(bin_, color='r', linestyle='dashed', linewidth=2)\n",
    "    return ax, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarsening = {\n",
    "    'distance': {'bins':range(15,86,10), 'cut': 'cut'}, # relax over\n",
    "    'year': {'bins': 5, 'cut': 'cut'}, # uniform so qcut=cut\n",
    "    'seasons': {'bins': [0,4,10,18,30], 'cut': 'cut'},\n",
    "    'temperature': {'bins': [-25,-5,5,15,25,35,45], 'cut': 'cut'},\n",
    "    'wind': {'bins': [-0.1,12,25,41], 'cut': 'cut'},\n",
    "    'pressure': {'bins': 3, 'cut': 'cut'},\n",
    "    'postseason': {'bins': 2, 'cut': 'cut'},\n",
    "    'iced': {'bins': 2, 'cut': 'cut'},\n",
    "    'precipitation': {'bins': 2, 'cut': 'cut'},\n",
    "    'altitude': {'bins': 2, 'cut': 'cut'},\n",
    "    'turf': {'bins': 2, 'cut': 'cut'},\n",
    "    'away_game': {'bins': 2, 'cut': 'cut'},\n",
    "    'altitude': {'bins': 2, 'cut': 'cut'},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var, coarsen in coarsening.items():\n",
    "    cut = coarsen['cut']\n",
    "    div = 2 if var in ('wind', 'temperature') else 1\n",
    "    ax, bins = var_plot(df, var, cuts=coarsen['bins'], bins=int(df[var].nunique()/div), func=eval(f'pd.{cut}'))\n",
    "    ax.tick_params(size=4)\n",
    "    # ax.set_title(f'Coarsening of {var}')\n",
    "    ax.set_xlabel(var, size=16)\n",
    "    # bins.cat.categories\n",
    "    plt.savefig(f'../images/coarsening/{var}.png')\n",
    "    plt.cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imb = None\n",
    "multi = {}\n",
    "n_matched = {}\n",
    "t_matched = {}\n",
    "uni = {}\n",
    "for t in binary:\n",
    "    cem = CEM(df, t, 'good', continuous, H=4)\n",
    "    ub = cem.univariate_imbalance(coarsening)\n",
    "    uni[t] = ub['imbalance'].round(3).astype(str)+ub['P>|z|'].apply(pp)\n",
    "    is_matched_ = cem.match(coarsening)>0\n",
    "    n_matched[t] = is_matched_.sum()\n",
    "    t_matched[t] = (df.loc[is_matched_, t] == 1).sum()/(df[t]==1).sum()*100\n",
    "    multi[t] = cem.imbalance(coarsening)\n",
    "\n",
    "df_imb = pd.DataFrame.from_dict(uni, orient='columns')\n",
    "df_imb = df_imb.append(pd.DataFrame(multi, index=['multivariate']))\n",
    "df_imb = df_imb.append(pd.DataFrame(n_matched, index=['% matched'])/len(df)*100)\n",
    "df_imb = df_imb.append(pd.DataFrame(t_matched, index=['% treatment matched']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_imb.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can probably be done a better way\n",
    "def get_formula(model, t, drop):\n",
    "    if model == 'simple':\n",
    "        formula = f'good ~ {t}'\n",
    "    elif model == 'main effects':\n",
    "        formula = 'good ~ '+ ' + '.join(df.drop(['good']+drop.get(t, []), axis=1).columns)\n",
    "    elif model == 'interactions' and t == 'turf':\n",
    "        formula = 'good ~ '+ ' + '.join(df.drop(['good']+drop.get(t, []), axis=1).columns) + ' + iced*pressure'\n",
    "    elif model == 'interactions':\n",
    "        formula = 'good ~ '+ ' + '.join(df.drop(['good']+drop.get(t, []), axis=1).columns) + ' + iced*pressure + altitude*distance'\n",
    "    elif model == 'full' and t == 'turf':\n",
    "        formula = 'good ~ '+ ' + '.join(df.drop(['good']+drop.get(t, []), axis=1).columns) +\\\n",
    "        '+ np.log(wind+1) + np.log(seasons) + iced*pressure'\n",
    "    elif model == 'full':\n",
    "        formula = 'good ~ '+ ' + '.join(df.drop(['good']+drop.get(t, []), axis=1).columns) +\\\n",
    "        ' + np.log(wind+1) + np.log(seasons) + np.log(distance) + iced*pressure + altitude*distance'\n",
    "    return formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get the regression weights from CEM\n",
    "weights = {t:CEM(df, t, 'good', continuous, H=4).match(coarsening) for t in binary}\n",
    "drop = {'altitude': ['turf'], 'turf': ['altitude']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regress!\n",
    "df_matched = pd.DataFrame(columns=['coefficient', 'P>|z|', 'bse', 'model', 'treatment'])\n",
    "results_matched = []\n",
    "models = ['simple', 'main effects', 'interactions', 'full']\n",
    "\n",
    "for t, model in itertools.product(binary, models):\n",
    "    formula = get_formula(model, t, drop)\n",
    "    w = weights[t]\n",
    "    glm = smf.glm(formula,\n",
    "                data=df[w > 0],\n",
    "                family=sm.families.Binomial(),\n",
    "                var_weights=w[w > 0])\n",
    "    result = glm.fit(method='bfgs', maxiter=1000)\n",
    "    results_matched.append({'model': model, 'result':result, 'treatment': t, 'formula': formula})\n",
    "    df_matched = pd.concat((df_matched, pd.DataFrame({'coefficient':result.params, \n",
    "                                                      'P>|z|':result.pvalues, \n",
    "                                                      'bse': result.bse,\n",
    "                                                      'model':model, \n",
    "                                                      'treatment':t})))\n",
    "\n",
    "df_matched.index.rename('covariate', inplace=True)\n",
    "df_matched.reset_index('covariate', inplace=True)\n",
    "results_matched = pd.DataFrame.from_records(results_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   covariate      coef          P>|z|       bse         model treatment\n0  Intercept  1.668793  3.994804e-239  0.050537        simple  altitude\n1   altitude  0.078904   5.521498e-01  0.132715        simple  altitude\n2  Intercept  5.430130   1.101308e-53  0.352021  main effects  altitude\n3   distance -0.107915   5.024400e-63  0.006440  main effects  altitude\n4       year  0.054354   2.638426e-09  0.009131  main effects  altitude",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>covariate</th>\n      <th>coef</th>\n      <th>P&gt;|z|</th>\n      <th>bse</th>\n      <th>model</th>\n      <th>treatment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Intercept</td>\n      <td>1.668793</td>\n      <td>3.994804e-239</td>\n      <td>0.050537</td>\n      <td>simple</td>\n      <td>altitude</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>altitude</td>\n      <td>0.078904</td>\n      <td>5.521498e-01</td>\n      <td>0.132715</td>\n      <td>simple</td>\n      <td>altitude</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Intercept</td>\n      <td>5.430130</td>\n      <td>1.101308e-53</td>\n      <td>0.352021</td>\n      <td>main effects</td>\n      <td>altitude</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>distance</td>\n      <td>-0.107915</td>\n      <td>5.024400e-63</td>\n      <td>0.006440</td>\n      <td>main effects</td>\n      <td>altitude</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>year</td>\n      <td>0.054354</td>\n      <td>2.638426e-09</td>\n      <td>0.009131</td>\n      <td>main effects</td>\n      <td>altitude</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 192
    }
   ],
   "source": [
    "df_matched.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          model                                             result treatment  \\\n0        simple  <statsmodels.genmod.generalized_linear_model.G...  altitude   \n1  main effects  <statsmodels.genmod.generalized_linear_model.G...  altitude   \n2  interactions  <statsmodels.genmod.generalized_linear_model.G...  altitude   \n3          full  <statsmodels.genmod.generalized_linear_model.G...  altitude   \n4        simple  <statsmodels.genmod.generalized_linear_model.G...      iced   \n\n                                             formula  \n0                                    good ~ altitude  \n1  good ~ distance + year + seasons + temperature...  \n2  good ~distance + year + seasons + temperature ...  \n3  good ~distance + year + seasons + temperature ...  \n4                                        good ~ iced  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>result</th>\n      <th>treatment</th>\n      <th>formula</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>simple</td>\n      <td>&lt;statsmodels.genmod.generalized_linear_model.G...</td>\n      <td>altitude</td>\n      <td>good ~ altitude</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>main effects</td>\n      <td>&lt;statsmodels.genmod.generalized_linear_model.G...</td>\n      <td>altitude</td>\n      <td>good ~ distance + year + seasons + temperature...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>interactions</td>\n      <td>&lt;statsmodels.genmod.generalized_linear_model.G...</td>\n      <td>altitude</td>\n      <td>good ~distance + year + seasons + temperature ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>full</td>\n      <td>&lt;statsmodels.genmod.generalized_linear_model.G...</td>\n      <td>altitude</td>\n      <td>good ~distance + year + seasons + temperature ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>simple</td>\n      <td>&lt;statsmodels.genmod.generalized_linear_model.G...</td>\n      <td>iced</td>\n      <td>good ~ iced</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 193
    }
   ],
   "source": [
    "results_matched.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables of Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unrelated(group):\n",
    "    # remove rows whose covariate they summarise that dont contain the treatment variable\n",
    "    t = group['treatment'].iloc[0]\n",
    "    group = group.loc[group['covariate'].str.contains(t, regex=False)]\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\\begin{tabular}{llllll}\n\\toprule\n     & model &     simple & main effects & interactions &       full \\\\\ntreatment & covariate &            &              &              &            \\\\\n\\midrule\naltitude & altitude &      0.079 &        0.218 &      1.837** &    2.154** \\\\\n     & altitude:distance &        NaN &          NaN &      -0.037* &   -0.045** \\\\\naway\\_game & away\\_game &     -0.035 &       -0.008 &       -0.007 &     -0.006 \\\\\niced & iced &  -0.355*** &    -0.222*** &       -0.075 &     -0.091 \\\\\n     & iced:pressure &        NaN &          NaN &       -0.106 &     -0.099 \\\\\npostseason & postseason &     -0.141 &        0.125 &        0.107 &      0.067 \\\\\nprecipitation & precipitation &  -0.305*** &    -0.265*** &    -0.264*** &  -0.255*** \\\\\nturf & turf &   0.158*** &      0.138** &      0.138** &   0.171*** \\\\\n\\bottomrule\n\\end{tabular}\n\n"
    }
   ],
   "source": [
    "# pivot on model again\n",
    "df_m = df_matched.loc[df_matched['covariate']!='Intercept', :]\n",
    "df_m = df_m.groupby('treatment').apply(drop_unrelated).reset_index(drop=True)\n",
    "df_m['coefficient'] = df_m['coefficient'].round(3).astype(str) + df_m['P>|z|'].apply(pp)\n",
    "df_m = df_m.loc[:,['covariate', 'coefficient', 'model', 'treatment']]\n",
    "df_piv = df_m.pivot_table(index=['treatment','covariate'], columns='model', values='coefficient', aggfunc=lambda x: x).loc[list(order_.keys()), ['simple','main effects', 'interactions', 'full']]\n",
    "print(df_piv.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'sf'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-197-5f66873c5207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mpooled_se_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpooled_var_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mz_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msate_m\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpooled_se_m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         \u001b[0mp_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# significance test for unmatched\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'sf'"
     ]
    }
   ],
   "source": [
    "sates = []\n",
    "\n",
    "for t in binary:\n",
    "\n",
    "    # num all units\n",
    "    n = len(df)\n",
    "\n",
    "    # num all treated and controls\n",
    "    n_t = (df[t]==1).sum()\n",
    "    n_c = (df[t]==0).sum()\n",
    "\n",
    "    # num matched units\n",
    "    m = (weights[t]>0).sum()\n",
    "\n",
    "    # num matched treated and controls\n",
    "    m_t = len(df.loc[(weights[t]>0) & (df[t]==1),:])\n",
    "    m_c = len(df.loc[(weights[t]>0) & (df[t]==0),:])\n",
    "\n",
    "    # matched and unmatched units\n",
    "    df_m = df.loc[(weights[t]>0), :] # matched\n",
    "    df_um = df.loc[(weights[t]==0), :] # unmatched\n",
    "\n",
    "    # matched treated units (observed or counterfactual)\n",
    "    df_m_treated = df_m.copy()\n",
    "    df_m_treated[t] = 1\n",
    "\n",
    "    # matched control units (observed or counterfactual)\n",
    "    df_m_control = df_m.copy()\n",
    "    df_m_control[t] = 0\n",
    "\n",
    "    # unmatched treated units (observed or counterfactual)\n",
    "    df_um_treated = df_um.copy()\n",
    "    df_um_treated[t] = 1\n",
    "\n",
    "    # unmatched control units (observed or counterfactual)\n",
    "    df_um_control = df_um.copy()\n",
    "    df_um_control[t] = 0\n",
    "\n",
    "    for _, row in results_matched.iterrows():\n",
    "        result = row['result']\n",
    "\n",
    "        if row['treatment'] != t:\n",
    "            continue\n",
    "\n",
    "        # matched predictions\n",
    "        treated_m = result.predict(df_m_treated)\n",
    "        control_m = result.predict(df_m_control)\n",
    "\n",
    "        # unmatched predictions\n",
    "        treated_um = result.predict(df_um_treated)\n",
    "        control_um = result.predict(df_um_control)\n",
    "\n",
    "        # sate for matched and unmatched units and their counterfactuals\n",
    "        sate_m = (treated_m-control_m).mean().round(3)\n",
    "        sate_um = (treated_um-control_um).mean().round(3)\n",
    "\n",
    "        # weighted sate combining matched and unmatched sates\n",
    "        sate_w = round((sate_m*m + sate_um*(n-m))/n,3)\n",
    "\n",
    "        # significance test for matched\n",
    "        pooled_m = (treated_m.mean() + control_m.mean())/2\n",
    "        pooled_var_m = 2*pooled_m*(1-pooled_m)/m\n",
    "        pooled_se_m = np.sqrt(pooled_var_m)\n",
    "        z_m = sate_m/pooled_se_m\n",
    "        p_m = norm.sf(abs(z_m))\n",
    "\n",
    "        # significance test for unmatched\n",
    "        pooled_um = (treated_um.mean() + control_um.mean())/2\n",
    "        pooled_var_um = 2*pooled_um*(1-pooled_um)/(n-m)\n",
    "        pooled_se_um = np.sqrt(pooled_var_um)\n",
    "        z_um = sate_um/pooled_se_um\n",
    "        p_um = norm.sf(abs(z_um))\n",
    "\n",
    "        # weighted significance test\n",
    "        pooled_var_w = (pooled_var_m*m + pooled_var_um*(n-m))/n\n",
    "        pooled_se_w = np.sqrt(pooled_var_w)\n",
    "        z_w = sate_w/pooled_se_w\n",
    "        p_w = norm.sf(abs(z_w))\n",
    "\n",
    "        sates.append({'treatment':t, 'model':row['model'], 'local SATE':str(sate_m)+pp(p_m), 'unmatched SATE':str(sate_um)+pp(p_um), 'weighted SATE':str(sate_w)+pp(p_w)})\n",
    "df_sate = pd.DataFrame.from_records(sates).set_index(['treatment', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_sate.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampale Average Treatment Effect on the Treated (Not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "satts = []\n",
    "\n",
    "for t in binary:\n",
    "\n",
    "    # all units\n",
    "    nT = (df[t]==1).sum()\n",
    "\n",
    "    # matched and unmatched treated units\n",
    "    df_t_m = df.loc[(weights[t]>0) & (df[t]==1), :] # matched\n",
    "    df_t_um = df.loc[(weights[t]==0) & (df[t]==1), :] # unmatched\n",
    "\n",
    "    # observed outcomes for matched and unmatched treated units\n",
    "    observed_m = df_t_m['good']\n",
    "    observed_um = df_t_um['good']\n",
    "    mT = len(observed_m) # matched treated units\n",
    "\n",
    "    # counterfactual data points for matched treated units\n",
    "    df_cf_m = df_t_m.copy()\n",
    "    df_cf_m[t] = 0\n",
    "\n",
    "    # counterfactuals for unmatched treated units\n",
    "    df_cf_um = df_t_um.copy()\n",
    "    df_cf_um[t] = 0\n",
    "\n",
    "    for _, row in results_matched.iterrows():\n",
    "        result = row['result']\n",
    "\n",
    "        if row['treatment'] != t:\n",
    "            continue\n",
    "\n",
    "        # true predictions\n",
    "        true_m = result.predict(df_t_m)\n",
    "        true_um = result.predict(df_t_um)\n",
    "\n",
    "        # potential outcome for matched and unmatched treated unit counterfactuals\n",
    "        potential_m = result.predict(df_cf_m)\n",
    "        potential_um = result.predict(df_cf_um)\n",
    "\n",
    "        # satt for matched and unmatched treated units and their counterfactuals\n",
    "        satt_m = (true_m-potential_m).mean().round(3)\n",
    "        satt_um = (true_um-potential_um).mean().round(3)\n",
    "\n",
    "        # weighted satt combining matched and unmatched satts\n",
    "        satt_w = round((satt_m*mT + satt_um*(nT-mT))/nT,3)\n",
    "\n",
    "        # t-test for matched and unmatched treated units and their counterfactuals. THIS IS POTENTIALLY VERY WRONG!\n",
    "        stat_m, p_m = ttest_rel(observed_m, potential_m)\n",
    "        stat_um, p_um = ttest_rel(observed_um, potential_um)\n",
    "        p_w = (p_m*mT + p_um*(nT-mT))/nT\n",
    "\n",
    "        satts.append({'treatment':t, 'model':row['model'], 'local satt':str(satt_m)+pp(p_m), 'unmatched satt':str(satt_um)+pp(p_um), 'weighted satt':str(satt_w)+pp(p_w)})\n",
    "df_satt = pd.DataFrame.from_records(satts).set_index(['treatment', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_satt.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Treatment Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = (('iced', 'pressure'), ('altitude', 'distance'))\n",
    "models = ('interactions', 'full')\n",
    "for (T, M), model in itertools.product(pairs, models):\n",
    "    vals = range(df[M].min(), df[M].max()+1)\n",
    "\n",
    "    result = df_matched.loc[(df_matched['model']==model) & (df_matched['treatment']==T), :] # all coefficients from regression\n",
    "    vc = results_matched[model].cov_params()\n",
    "\n",
    "    ATE, SE = zip(*[CATE(result, T, M, d, vc) for d in vals])\n",
    "\n",
    "    fig, axes = plt.subplots(2,1)\n",
    "    sns.distplot(df.loc[weights[T]>0, M], kde=False, ax=axes[1])\n",
    "    ax = sns.lineplot(x=vals, y=ATE, ax=axes[0])\n",
    "    lb = np.array(ATE) - 1.96*np.array(SE)\n",
    "    ub = np.array(ATE) + 1.96*np.array(SE)\n",
    "    axes[0].fill_between(vals,lb,ub, alpha=0.3)\n",
    "    ax.set_title(f'Marginal effect of {T} with {M}')\n",
    "    axes[1].set_xlabel(M)\n",
    "    ax.set_ylabel(f'Marginal effect of {T}')\n",
    "    axes[1].set_ylabel('Count')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.hlines(0,df[M].min(), df[M].max(), colors='r', alpha=0.5, linestyles='dashed')\n",
    "    plt.savefig(f'../images/matched_{T}/{M}_{model}.png')\n",
    "    plt.cla()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pres = df.loc[weights['iced']>0,'pressure'].value_counts().sort_index(ascending=True).round(3).to_frame()\n",
    "pres.index.rename('Level', inplace=True)\n",
    "pres = pres.rename(columns={'pressure':'Count'})\n",
    "print(pres.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ('main effects', 'interactions', 'full')\n",
    "for model, t in itertools.product(models, binary):\n",
    "    on = 'pred'\n",
    "    df_ = df.loc[weights[t]>0, :] # matched\n",
    "    resid = binned_residuals(results_matched.loc[(results_matched['model']==model) & (results_matched['treatment']==t), 'result'].iloc[0], df_.drop('good', axis=1), df_['good'], bins=None, on=on)\n",
    "    pct = round(resid['inside'].mean()*100,1)\n",
    "    ax = plot_binned_residuals(resid, on=on)\n",
    "    ax.set_title(f'Residuals for {model} model after matching on {t} ({pct}% inside)')\n",
    "    model = '_'.join(model.split())\n",
    "    plt.savefig(f'../images/matched_residuals/{model}_{t}_{on}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I'd love to generalise the process so that we dont need 2 sections to this notebook. I.e. Unmatched vs Matched. There's a lot of repeated code."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitcondapymc3conda6670677869c246b299085920d157fd45",
   "display_name": "Python 3.7.6 64-bit ('conda_pymc3': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}