{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitcondapymc3conda6670677869c246b299085920d157fd45",
   "display_name": "Python 3.7.6 64-bit ('conda_pymc3': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passer Ratings: Physical attributes ü§ô üí™ üßç\n",
    "\n",
    "Hypothesis: Hand size/height/arm length affects average career passer rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "import pymc3 as pm\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>attempts</th>\n      <th>avg_rating</th>\n      <th>sack_rate</th>\n      <th>alt_rate</th>\n      <th>precip_rate</th>\n      <th>turf_rate</th>\n      <th>wind_rate</th>\n      <th>away_rate</th>\n      <th>temp</th>\n      <th>height</th>\n      <th>arm</th>\n      <th>hand</th>\n      <th>dpos</th>\n      <th>seasons</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>DB-3800-2011</th>\n      <td>2011</td>\n      <td>763.0</td>\n      <td>110.6</td>\n      <td>0.0365</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.7222</td>\n      <td>2.333333</td>\n      <td>0.5000</td>\n      <td>68.944444</td>\n      <td>72.0</td>\n      <td>31.250</td>\n      <td>10.00</td>\n      <td>32</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>PM-0200-2013</th>\n      <td>2013</td>\n      <td>787.0</td>\n      <td>111.7</td>\n      <td>0.0223</td>\n      <td>0.5263</td>\n      <td>0.0526</td>\n      <td>0.2632</td>\n      <td>7.526316</td>\n      <td>0.4211</td>\n      <td>57.578947</td>\n      <td>77.0</td>\n      <td>31.500</td>\n      <td>10.13</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>EM-0200-2011</th>\n      <td>2011</td>\n      <td>752.0</td>\n      <td>95.1</td>\n      <td>0.0493</td>\n      <td>0.0000</td>\n      <td>0.1000</td>\n      <td>0.7500</td>\n      <td>7.850000</td>\n      <td>0.5500</td>\n      <td>57.550000</td>\n      <td>77.0</td>\n      <td>30.750</td>\n      <td>9.75</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>TB-2300-2011</th>\n      <td>2011</td>\n      <td>722.0</td>\n      <td>104.8</td>\n      <td>0.0462</td>\n      <td>0.0526</td>\n      <td>0.0000</td>\n      <td>0.6316</td>\n      <td>7.842105</td>\n      <td>0.4211</td>\n      <td>55.000000</td>\n      <td>76.0</td>\n      <td>32.750</td>\n      <td>9.38</td>\n      <td>199</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>MR-2500-2016</th>\n      <td>2016</td>\n      <td>632.0</td>\n      <td>119.9</td>\n      <td>0.0661</td>\n      <td>0.0526</td>\n      <td>0.0526</td>\n      <td>0.7368</td>\n      <td>2.052632</td>\n      <td>0.4211</td>\n      <td>68.611111</td>\n      <td>77.0</td>\n      <td>32.375</td>\n      <td>9.50</td>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>TD-1400-2007</th>\n      <td>2007</td>\n      <td>219.0</td>\n      <td>55.1</td>\n      <td>0.1093</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.1429</td>\n      <td>5.285714</td>\n      <td>0.4286</td>\n      <td>60.000000</td>\n      <td>76.0</td>\n      <td>32.250</td>\n      <td>9.63</td>\n      <td>6</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>MM-2800-2005</th>\n      <td>2005</td>\n      <td>207.0</td>\n      <td>55.2</td>\n      <td>0.0841</td>\n      <td>0.0000</td>\n      <td>0.1111</td>\n      <td>0.2222</td>\n      <td>4.888889</td>\n      <td>0.3333</td>\n      <td>55.555556</td>\n      <td>74.0</td>\n      <td>32.000</td>\n      <td>9.75</td>\n      <td>149</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>JS-3700-2012</th>\n      <td>2012</td>\n      <td>201.0</td>\n      <td>55.4</td>\n      <td>0.0694</td>\n      <td>0.0000</td>\n      <td>0.1429</td>\n      <td>0.5714</td>\n      <td>2.857143</td>\n      <td>0.5714</td>\n      <td>64.428571</td>\n      <td>77.0</td>\n      <td>32.000</td>\n      <td>9.75</td>\n      <td>285</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>SM-2400-2007</th>\n      <td>2007</td>\n      <td>205.0</td>\n      <td>73.9</td>\n      <td>0.0463</td>\n      <td>0.0000</td>\n      <td>0.1667</td>\n      <td>0.1667</td>\n      <td>5.833333</td>\n      <td>0.6667</td>\n      <td>66.500000</td>\n      <td>74.0</td>\n      <td>32.250</td>\n      <td>10.50</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>JG-1850-2016</th>\n      <td>2016</td>\n      <td>205.0</td>\n      <td>63.6</td>\n      <td>0.1126</td>\n      <td>0.0000</td>\n      <td>0.1429</td>\n      <td>0.4286</td>\n      <td>3.142857</td>\n      <td>0.4286</td>\n      <td>54.333333</td>\n      <td>76.0</td>\n      <td>32.750</td>\n      <td>9.00</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>610 rows √ó 15 columns</p>\n</div>",
      "text/plain": "              year  attempts  avg_rating  sack_rate  alt_rate  precip_rate  \\\nDB-3800-2011  2011     763.0       110.6     0.0365    0.0000       0.0000   \nPM-0200-2013  2013     787.0       111.7     0.0223    0.5263       0.0526   \nEM-0200-2011  2011     752.0        95.1     0.0493    0.0000       0.1000   \nTB-2300-2011  2011     722.0       104.8     0.0462    0.0526       0.0000   \nMR-2500-2016  2016     632.0       119.9     0.0661    0.0526       0.0526   \n...            ...       ...         ...        ...       ...          ...   \nTD-1400-2007  2007     219.0        55.1     0.1093    0.0000       0.0000   \nMM-2800-2005  2005     207.0        55.2     0.0841    0.0000       0.1111   \nJS-3700-2012  2012     201.0        55.4     0.0694    0.0000       0.1429   \nSM-2400-2007  2007     205.0        73.9     0.0463    0.0000       0.1667   \nJG-1850-2016  2016     205.0        63.6     0.1126    0.0000       0.1429   \n\n              turf_rate  wind_rate  away_rate       temp  height     arm  \\\nDB-3800-2011     0.7222   2.333333     0.5000  68.944444    72.0  31.250   \nPM-0200-2013     0.2632   7.526316     0.4211  57.578947    77.0  31.500   \nEM-0200-2011     0.7500   7.850000     0.5500  57.550000    77.0  30.750   \nTB-2300-2011     0.6316   7.842105     0.4211  55.000000    76.0  32.750   \nMR-2500-2016     0.7368   2.052632     0.4211  68.611111    77.0  32.375   \n...                 ...        ...        ...        ...     ...     ...   \nTD-1400-2007     0.1429   5.285714     0.4286  60.000000    76.0  32.250   \nMM-2800-2005     0.2222   4.888889     0.3333  55.555556    74.0  32.000   \nJS-3700-2012     0.5714   2.857143     0.5714  64.428571    77.0  32.000   \nSM-2400-2007     0.1667   5.833333     0.6667  66.500000    74.0  32.250   \nJG-1850-2016     0.4286   3.142857     0.4286  54.333333    76.0  32.750   \n\n               hand  dpos  seasons  \nDB-3800-2011  10.00    32       11  \nPM-0200-2013  10.13     1       16  \nEM-0200-2011   9.75     1        8  \nTB-2300-2011   9.38   199       12  \nMR-2500-2016   9.50     3        9  \n...             ...   ...      ...  \nTD-1400-2007   9.63     6       14  \nMM-2800-2005   9.75   149        5  \nJS-3700-2012   9.75   285        3  \nSM-2400-2007  10.50     3       13  \nJG-1850-2016   9.00     1        1  \n\n[610 rows x 15 columns]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/passer_ratings.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we dichotamise the variable of interest. For example, we may filter to only include big or small handed players. We say small hand QB's are those in the bottom 1/3rd, and large hands are the top 1/3rd.\n",
    "\n",
    "Height and arm length are postively correlated (0.45), so it's a little difficult to control for one when investigating the other. Height is of bigger interest than arm, and we suspect it is a bigger influence. However we see the drawback in not controlling for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on = 'warm' # the name of the dichotomous variable\n",
    "original = 'temp' # the original variable name\n",
    "\n",
    "# specifically for height study\n",
    "# df_exp.drop('arm', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = np.percentile(df_exp[original], q=66)\n",
    "small = np.percentile(df_exp[original], q=33)\n",
    "df_exp = df_exp.loc[(df_exp[original]>=big) | (df_exp[original]<=small), :] # only extreme values\n",
    "df_exp[on] = df_exp[original]>=big\n",
    "df_exp = df_exp.drop(original, axis=1)\n",
    "print(big, small)\n",
    "df_exp[on].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be done in R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarsened Exact Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in from field_goals.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the mahalanobis frontier to see how the aggregate mahalanobis distance is changing with radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.matching import mahalanobis_frontier, match_by_distance\n",
    "df_exp[on] = df_exp[on].astype(bool)\n",
    "df_mf = mahalanobis_frontier(df_exp.drop('avg_rating', axis=1), on)\n",
    "df_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='pruned controls', y='AMD', data=df_mf)\n",
    "plt.title('Mahalanobis Matching Frontier')\n",
    "plt.show()\n",
    "plt.title('Mahalanobis Matching Frontier')\n",
    "sns.lineplot(x='pruned treatments', y='AMD', data=df_mf)\n",
    "plt.show()\n",
    "plt.title('Mahalanobis Matching Frontier')\n",
    "sns.lineplot(x='radius', y='AMD', data=df_mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a reasonable radius/caliper to minimise difference in marginal distributions but also keep as many controls as possible. This is a little difficult because we're not working with very large sample sizes as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched = match_by_distance(df_exp, on, 'avg_rating', 'mahalanobis', caliper=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.matching import covariate_dists\n",
    "covariate_dists(df_matched.drop('avg_rating', axis=1), on=on, kde=False, hist=True, n_bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a t-test for difference of sample means. We're more interested in distribution similarity, but large difference of means can indicate problems. The p value is the probability of observing such a difference between sample means given their population means are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "for col in df_matched.drop(['avg_rating', on], axis=1).columns:\n",
    "    rvs1 = df_matched.loc[df_matched[on], col]\n",
    "    rvs2 = df_matched.loc[~df_matched[on], col]\n",
    "    _, p = ttest_ind(rvs1, rvs2, equal_var = False)\n",
    "    print(f'P(x|H0) for {col}: {round(p,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treatment = df_matched.loc[df_matched[on],:]\n",
    "df_control = df_matched.loc[~df_matched[on], :]\n",
    "print(len(df_treatment), f'{on} samples.', len(df_control), f'not {on} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We'll use the BEST method for comparing means of the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = df_treatment['avg_rating']\n",
    "control = df_control['avg_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,2, sharey=True, sharex=True)\n",
    "sns.distplot(treatment, ax=axes[0])\n",
    "axes[0].set_title(f'Passer rating - {on}')\n",
    "sns.distplot(control, ax=axes[1])\n",
    "axes[1].set_title(f'Passer rating - not {on}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the relatively small sample sizes we assume our distributions are of the students-t distribution (Kruschke).\n",
    "The students-t has a mean, variance, and degree-of-freedom.\n",
    "The degree of freedom control the normality of the data (larger dof converges to normal distribution).\n",
    "\n",
    "Lets set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors on the mean\n",
    "m_mu = pd.concat([control,treatment]).mean()\n",
    "m_sd = pd.concat([control,treatment]).std()\n",
    "\n",
    "with pm.Model() as model:\n",
    "    treatment_mean = pm.Normal('treatment_mean', mu=m_mu, sd=m_sd)\n",
    "    control_mean = pm.Normal('control_mean', mu=m_mu, sd=m_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors on the standard deviation\n",
    "sd_low = 1\n",
    "sd_high = 30\n",
    "\n",
    "with model:\n",
    "    treatment_std = pm.Uniform('treatment_std', lower=sd_low, upper=sd_high)\n",
    "    control_std = pm.Uniform('control_std', lower=sd_low, upper=sd_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared prior on the degree of freedom parameter\n",
    "with model:\n",
    "    v = pm.Exponential('v_minus_one', 1/29.) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymc3 paramaterises students t with precision, rather than standard deviation (lambda = 1/sigma^2)\n",
    "with model:\n",
    "    treatment_lambda = treatment_std**-2  # deterministic\n",
    "    control_lambda = control_std**-2 # deterministic\n",
    "\n",
    "    treatment_rating = pm.StudentT(f'{on}', nu=v, mu=treatment_mean, lam=treatment_lambda, observed=treatment)\n",
    "    control_rating = pm.StudentT(f'not {on}', nu=v, mu=control_mean, lam=control_lambda, observed=control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    # our deterministic values, we could just have easily done this with the traces.\n",
    "    diff_of_means = pm.Deterministic('difference_of_means', treatment_mean - control_mean)\n",
    "    diff_of_stds = pm.Deterministic('difference_of_stds', treatment_std - control_std)\n",
    "    effect_size = pm.Deterministic('effect_size',\n",
    "                                   diff_of_means / np.sqrt((treatment_std**2 + control_std**2) / 2)) # hard to interpret but is difference scaled by pooled variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(2000) # NUTS sampling for filling our posterior\n",
    "\n",
    "    # dump the trace\n",
    "    today = dt.now().strftime('%y%m%d')\n",
    "    with open(f'../results/trace_{on}_{today}.pckle', 'wb') as f:\n",
    "        pickle.dump(trace, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, var_names=['difference_of_means','difference_of_stds', 'effect_size'],\n",
    "                  ref_val=0,\n",
    "                  color='#87ceeb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the diagnostics show that the sampling went as suspected with no issues (Rhat ~ 1)\n",
    "from util.stats import summary\n",
    "summary_ = summary(trace)\n",
    "summary_ # error out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Relative difference in means/lift."
   ]
  }
 ]
}