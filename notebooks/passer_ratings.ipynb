{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bitcondapymc3conda6670677869c246b299085920d157fd45",
   "display_name": "Python 3.7.6 64-bit ('conda_pymc3': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passer Ratings: Physical attributes 🤙 💪 🧍\n",
    "\n",
    "Hypothesis: Hand size/height/arm length affects average career passer rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "import sys\n",
    "import pickle\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "import pymc3 as pm\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "\n",
    "We drop a QB's season if they had less than 50 attempts, as that's too small sample size to be a reasonable reflection of skill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user='root', password='mOntie20!mysql', host='127.0.0.1', database='nfl')\n",
    "sql = open('../sql/qb_season_ratings.sql', 'r').read()\n",
    "df = pd.read_sql(sql, cnx)\n",
    "df = df.loc[:,~df.columns.duplicated()][df['attempts']>50].set_index(['player','year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean\n",
    "\n",
    "The dataset uses empty strings as missing values. We'll change that to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>attempts</th>\n      <th>completions</th>\n      <th>yards</th>\n      <th>interceptions</th>\n      <th>TD</th>\n      <th>avg_rating</th>\n      <th>sack_rate</th>\n      <th>alt_rate</th>\n      <th>precip_rate</th>\n      <th>turf_rate</th>\n      <th>...</th>\n      <th>vertical</th>\n      <th>broad</th>\n      <th>shuttle</th>\n      <th>cone</th>\n      <th>arm</th>\n      <th>hand</th>\n      <th>dpos</th>\n      <th>start</th>\n      <th>jnum</th>\n      <th>dcp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>...</td>\n      <td>1014.000000</td>\n      <td>528.000000</td>\n      <td>551.000000</td>\n      <td>539.000000</td>\n      <td>485.000000</td>\n      <td>515.00000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n      <td>1014.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>346.623274</td>\n      <td>211.994083</td>\n      <td>2435.874753</td>\n      <td>9.706114</td>\n      <td>14.737673</td>\n      <td>80.376627</td>\n      <td>0.067296</td>\n      <td>0.030572</td>\n      <td>0.084831</td>\n      <td>0.423961</td>\n      <td>...</td>\n      <td>17.377712</td>\n      <td>111.323864</td>\n      <td>4.283013</td>\n      <td>7.121744</td>\n      <td>32.135309</td>\n      <td>9.59213</td>\n      <td>57.834320</td>\n      <td>2003.830375</td>\n      <td>3.279093</td>\n      <td>0.696252</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>197.733500</td>\n      <td>128.141549</td>\n      <td>1511.868073</td>\n      <td>5.688563</td>\n      <td>11.215744</td>\n      <td>15.095219</td>\n      <td>0.027190</td>\n      <td>0.094902</td>\n      <td>0.109693</td>\n      <td>0.269861</td>\n      <td>...</td>\n      <td>16.140787</td>\n      <td>6.963120</td>\n      <td>0.167032</td>\n      <td>0.229315</td>\n      <td>1.047378</td>\n      <td>0.46930</td>\n      <td>73.885134</td>\n      <td>7.164602</td>\n      <td>5.075347</td>\n      <td>1.101218</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>51.000000</td>\n      <td>18.000000</td>\n      <td>167.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>16.700000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>96.000000</td>\n      <td>3.900000</td>\n      <td>6.660000</td>\n      <td>28.500000</td>\n      <td>8.25000</td>\n      <td>0.000000</td>\n      <td>1985.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>160.250000</td>\n      <td>93.000000</td>\n      <td>1020.750000</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>71.025000</td>\n      <td>0.048425</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.200000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>106.000000</td>\n      <td>4.175000</td>\n      <td>6.950000</td>\n      <td>31.250000</td>\n      <td>9.26800</td>\n      <td>1.000000</td>\n      <td>1999.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>341.500000</td>\n      <td>204.000000</td>\n      <td>2321.500000</td>\n      <td>9.000000</td>\n      <td>12.000000</td>\n      <td>81.050000</td>\n      <td>0.064000</td>\n      <td>0.000000</td>\n      <td>0.058800</td>\n      <td>0.333300</td>\n      <td>...</td>\n      <td>26.500000</td>\n      <td>111.000000</td>\n      <td>4.280000</td>\n      <td>7.110000</td>\n      <td>32.000000</td>\n      <td>9.50000</td>\n      <td>22.000000</td>\n      <td>2004.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>525.750000</td>\n      <td>320.000000</td>\n      <td>3705.750000</td>\n      <td>14.000000</td>\n      <td>22.000000</td>\n      <td>90.600000</td>\n      <td>0.082775</td>\n      <td>0.000000</td>\n      <td>0.133300</td>\n      <td>0.666700</td>\n      <td>...</td>\n      <td>32.500000</td>\n      <td>116.000000</td>\n      <td>4.380000</td>\n      <td>7.210000</td>\n      <td>32.875000</td>\n      <td>9.87500</td>\n      <td>93.000000</td>\n      <td>2009.000000</td>\n      <td>7.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>787.000000</td>\n      <td>541.000000</td>\n      <td>6404.000000</td>\n      <td>30.000000</td>\n      <td>60.000000</td>\n      <td>121.000000</td>\n      <td>0.194000</td>\n      <td>0.750000</td>\n      <td>0.750000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>39.000000</td>\n      <td>127.000000</td>\n      <td>4.780000</td>\n      <td>7.800000</td>\n      <td>35.000000</td>\n      <td>10.87500</td>\n      <td>285.000000</td>\n      <td>2019.000000</td>\n      <td>19.000000</td>\n      <td>5.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 27 columns</p>\n</div>",
      "text/plain": "          attempts  completions        yards  interceptions           TD  \\\ncount  1014.000000  1014.000000  1014.000000    1014.000000  1014.000000   \nmean    346.623274   211.994083  2435.874753       9.706114    14.737673   \nstd     197.733500   128.141549  1511.868073       5.688563    11.215744   \nmin      51.000000    18.000000   167.000000       0.000000     0.000000   \n25%     160.250000    93.000000  1020.750000       5.000000     5.000000   \n50%     341.500000   204.000000  2321.500000       9.000000    12.000000   \n75%     525.750000   320.000000  3705.750000      14.000000    22.000000   \nmax     787.000000   541.000000  6404.000000      30.000000    60.000000   \n\n        avg_rating    sack_rate     alt_rate  precip_rate    turf_rate  ...  \\\ncount  1014.000000  1014.000000  1014.000000  1014.000000  1014.000000  ...   \nmean     80.376627     0.067296     0.030572     0.084831     0.423961  ...   \nstd      15.095219     0.027190     0.094902     0.109693     0.269861  ...   \nmin      16.700000     0.000000     0.000000     0.000000     0.000000  ...   \n25%      71.025000     0.048425     0.000000     0.000000     0.200000  ...   \n50%      81.050000     0.064000     0.000000     0.058800     0.333300  ...   \n75%      90.600000     0.082775     0.000000     0.133300     0.666700  ...   \nmax     121.000000     0.194000     0.750000     0.750000     1.000000  ...   \n\n          vertical       broad     shuttle        cone         arm       hand  \\\ncount  1014.000000  528.000000  551.000000  539.000000  485.000000  515.00000   \nmean     17.377712  111.323864    4.283013    7.121744   32.135309    9.59213   \nstd      16.140787    6.963120    0.167032    0.229315    1.047378    0.46930   \nmin       0.000000   96.000000    3.900000    6.660000   28.500000    8.25000   \n25%       0.000000  106.000000    4.175000    6.950000   31.250000    9.26800   \n50%      26.500000  111.000000    4.280000    7.110000   32.000000    9.50000   \n75%      32.500000  116.000000    4.380000    7.210000   32.875000    9.87500   \nmax      39.000000  127.000000    4.780000    7.800000   35.000000   10.87500   \n\n              dpos        start         jnum          dcp  \ncount  1014.000000  1014.000000  1014.000000  1014.000000  \nmean     57.834320  2003.830375     3.279093     0.696252  \nstd      73.885134     7.164602     5.075347     1.101218  \nmin       0.000000  1985.000000     0.000000     0.000000  \n25%       1.000000  1999.000000     0.000000     0.000000  \n50%      22.000000  2004.000000     0.000000     0.000000  \n75%      93.000000  2009.000000     7.000000     1.000000  \nmax     285.000000  2019.000000    19.000000     5.000000  \n\n[8 rows x 27 columns]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.apply(lambda x: x.replace('', np.nan))\n",
    "\n",
    "# physical\n",
    "df.loc[df['hand']<1, 'hand'] = np.nan\n",
    "df['hand'] = df.groupby('player')['hand'].apply(lambda x: x.fillna(method='ffill'))\n",
    "df.loc[df['height']<1, 'height'] = np.nan\n",
    "df.loc[df['weight']<1, 'weight'] = np.nan\n",
    "df.loc[df['arm']<1, 'arm'] = np.nan\n",
    "\n",
    "# combine\n",
    "df.loc[df['broad']<1, 'broad'] = np.nan\n",
    "df.loc[df['cone']<1, 'cone'] = np.nan\n",
    "df.loc[df['shuttle']<1, 'shuttle'] = np.nan \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nMultiIndex: 1014 entries, ('DB-3800', 2011) to ('SW-2400', 2000)\nData columns (total 38 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   attempts       1014 non-null   float64\n 1   completions    1014 non-null   float64\n 2   yards          1014 non-null   float64\n 3   interceptions  1014 non-null   float64\n 4   TD             1014 non-null   float64\n 5   avg_rating     1014 non-null   float64\n 6   sack_rate      1014 non-null   float64\n 7   alt_rate       1014 non-null   float64\n 8   precip_rate    1014 non-null   float64\n 9   turf_rate      1014 non-null   float64\n 10  wind_rate      1014 non-null   float64\n 11  away_rate      1014 non-null   float64\n 12  temp           1014 non-null   float64\n 13  fname          1014 non-null   object \n 14  lname          1014 non-null   object \n 15  pname          1014 non-null   object \n 16  pos1           1014 non-null   object \n 17  pos2           83 non-null     object \n 18  height         1014 non-null   float64\n 19  weight         1014 non-null   float64\n 20  dob            1014 non-null   object \n 21  forty          1014 non-null   float64\n 22  bench          1014 non-null   int64  \n 23  vertical       1014 non-null   float64\n 24  broad          528 non-null    float64\n 25  shuttle        551 non-null    float64\n 26  cone           539 non-null    float64\n 27  arm            485 non-null    float64\n 28  hand           515 non-null    float64\n 29  dpos           1014 non-null   int64  \n 30  col            1014 non-null   object \n 31  dv             995 non-null    object \n 32  start          1014 non-null   int64  \n 33  cteam          1014 non-null   object \n 34  posd           1014 non-null   object \n 35  jnum           1014 non-null   int64  \n 36  dcp            1014 non-null   int64  \n 37  nflid          1014 non-null   object \ndtypes: float64(22), int64(5), object(11)\nmemory usage: 346.1+ KB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets load in combine data we scraped outside of this notebook. The combine data includes physical attributes measured at the start of the players career. We add these features to the QB frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill(group, cols, data):\n",
    "    group = group.reset_index(-1)\n",
    "    for col in cols:\n",
    "        if col not in group.columns:\n",
    "            group[col] = np.nan\n",
    "        group[col] = group[col].fillna(data[col])\n",
    "    group = group.set_index('year', append=True)\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fname</th>\n      <th>lname</th>\n      <th>arm</th>\n      <th>hand</th>\n      <th>shuttle</th>\n      <th>cone</th>\n      <th>broad</th>\n      <th>wonderlic</th>\n      <th>ball_speed</th>\n    </tr>\n    <tr>\n      <th>player</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AB-2900</th>\n      <td>Aaron</td>\n      <td>Brooks</td>\n      <td>32.000</td>\n      <td>9.500</td>\n      <td>4.29</td>\n      <td>7.52</td>\n      <td>120.0</td>\n      <td>17.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>AF-0300</th>\n      <td>A.J.</td>\n      <td>Feeley</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4.16</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>AS-1400</th>\n      <td>Akili</td>\n      <td>Smith</td>\n      <td>32.250</td>\n      <td>9.750</td>\n      <td>4.29</td>\n      <td>6.99</td>\n      <td>114.0</td>\n      <td>26.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>AS-1600</th>\n      <td>Alex</td>\n      <td>Smith</td>\n      <td>31.750</td>\n      <td>9.375</td>\n      <td>3.97</td>\n      <td>6.82</td>\n      <td>113.0</td>\n      <td>40.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>AV-0200</th>\n      <td>Alex</td>\n      <td>Van Pelt</td>\n      <td>31.880</td>\n      <td>9.750</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>TS-2600</th>\n      <td>Troy</td>\n      <td>Smith</td>\n      <td>31.000</td>\n      <td>8.250</td>\n      <td>4.24</td>\n      <td>7.25</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>TT-0900</th>\n      <td>Tyler</td>\n      <td>Thigpen</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>VT-0200</th>\n      <td>Vinny</td>\n      <td>Testaverde</td>\n      <td>33.500</td>\n      <td>10.000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>VY-0100</th>\n      <td>Vince</td>\n      <td>Young</td>\n      <td>33.250</td>\n      <td>9.130</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>ZM-0150</th>\n      <td>Zach</td>\n      <td>Mettenberger</td>\n      <td>32.375</td>\n      <td>9.750</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>160 rows × 9 columns</p>\n</div>",
      "text/plain": "         fname         lname     arm    hand  shuttle  cone  broad  wonderlic  \\\nplayer                                                                          \nAB-2900  Aaron        Brooks  32.000   9.500     4.29  7.52  120.0       17.0   \nAF-0300   A.J.        Feeley     NaN     NaN     4.16   NaN    NaN        NaN   \nAS-1400  Akili         Smith  32.250   9.750     4.29  6.99  114.0       26.0   \nAS-1600   Alex         Smith  31.750   9.375     3.97  6.82  113.0       40.0   \nAV-0200   Alex      Van Pelt  31.880   9.750      NaN   NaN    NaN        NaN   \n...        ...           ...     ...     ...      ...   ...    ...        ...   \nTS-2600   Troy         Smith  31.000   8.250     4.24  7.25    NaN        NaN   \nTT-0900  Tyler       Thigpen     NaN     NaN      NaN   NaN    NaN        NaN   \nVT-0200  Vinny    Testaverde  33.500  10.000      NaN   NaN    NaN        NaN   \nVY-0100  Vince         Young  33.250   9.130      NaN   NaN    NaN       15.0   \nZM-0150   Zach  Mettenberger  32.375   9.750      NaN   NaN    NaN        NaN   \n\n         ball_speed  \nplayer               \nAB-2900         NaN  \nAF-0300         NaN  \nAS-1400         NaN  \nAS-1600         NaN  \nAV-0200         NaN  \n...             ...  \nTS-2600         NaN  \nTT-0900         NaN  \nVT-0200         NaN  \nVY-0100         NaN  \nZM-0150         NaN  \n\n[160 rows x 9 columns]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qb_combine = pd.read_csv(f'../data/combine_qb_200309.csv', index_col=0)\n",
    "cols = qb_combine.drop(['fname','lname'], axis=1).columns.values\n",
    "qb_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('player').apply(lambda x: fill(x, cols, qb_combine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "year\n2001    9.5\n2004    9.5\n2002    9.5\n2003    9.5\n2005    9.5\n2000    9.5\n2006    9.5\nName: hand, dtype: float64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['AB-2900', 'hand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nMultiIndex: 1014 entries, ('DB-3800', 2011) to ('SW-2400', 2000)\nData columns (total 40 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   attempts       1014 non-null   float64\n 1   completions    1014 non-null   float64\n 2   yards          1014 non-null   float64\n 3   interceptions  1014 non-null   float64\n 4   TD             1014 non-null   float64\n 5   avg_rating     1014 non-null   float64\n 6   sack_rate      1014 non-null   float64\n 7   alt_rate       1014 non-null   float64\n 8   precip_rate    1014 non-null   float64\n 9   turf_rate      1014 non-null   float64\n 10  wind_rate      1014 non-null   float64\n 11  away_rate      1014 non-null   float64\n 12  temp           1014 non-null   float64\n 13  fname          1014 non-null   object \n 14  lname          1014 non-null   object \n 15  pname          1014 non-null   object \n 16  pos1           1014 non-null   object \n 17  pos2           83 non-null     object \n 18  height         1014 non-null   float64\n 19  weight         1014 non-null   float64\n 20  dob            1014 non-null   object \n 21  forty          1014 non-null   float64\n 22  bench          1014 non-null   int64  \n 23  vertical       1014 non-null   float64\n 24  broad          528 non-null    float64\n 25  shuttle        652 non-null    float64\n 26  cone           555 non-null    float64\n 27  arm            873 non-null    float64\n 28  hand           881 non-null    float64\n 29  dpos           1014 non-null   int64  \n 30  col            1014 non-null   object \n 31  dv             995 non-null    object \n 32  start          1014 non-null   int64  \n 33  cteam          1014 non-null   object \n 34  posd           1014 non-null   object \n 35  jnum           1014 non-null   int64  \n 36  dcp            1014 non-null   int64  \n 37  nflid          1014 non-null   object \n 38  wonderlic      382 non-null    float64\n 39  ball_speed     16 non-null     float64\ndtypes: float64(24), int64(5), object(11)\nmemory usage: 372.6+ KB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>player</th>\n      <th>year</th>\n      <th>attempts</th>\n      <th>avg_rating</th>\n      <th>sack_rate</th>\n      <th>alt_rate</th>\n      <th>precip_rate</th>\n      <th>turf_rate</th>\n      <th>wind_rate</th>\n      <th>away_rate</th>\n      <th>temp</th>\n      <th>height</th>\n      <th>arm</th>\n      <th>start</th>\n      <th>hand</th>\n      <th>dpos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>DB-3800</td>\n      <td>2011</td>\n      <td>763.0</td>\n      <td>110.6</td>\n      <td>0.0365</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.7222</td>\n      <td>2.333333</td>\n      <td>0.5000</td>\n      <td>68.944444</td>\n      <td>72.0</td>\n      <td>31.250</td>\n      <td>2001</td>\n      <td>10.000</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>PM-0200</td>\n      <td>2013</td>\n      <td>787.0</td>\n      <td>111.7</td>\n      <td>0.0223</td>\n      <td>0.5263</td>\n      <td>0.0526</td>\n      <td>0.2632</td>\n      <td>7.526316</td>\n      <td>0.4211</td>\n      <td>57.578947</td>\n      <td>77.0</td>\n      <td>31.500</td>\n      <td>1998</td>\n      <td>10.130</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>EM-0200</td>\n      <td>2011</td>\n      <td>752.0</td>\n      <td>95.1</td>\n      <td>0.0493</td>\n      <td>0.0000</td>\n      <td>0.1000</td>\n      <td>0.7500</td>\n      <td>7.850000</td>\n      <td>0.5500</td>\n      <td>57.550000</td>\n      <td>77.0</td>\n      <td>30.750</td>\n      <td>2004</td>\n      <td>9.750</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TB-2300</td>\n      <td>2011</td>\n      <td>722.0</td>\n      <td>104.8</td>\n      <td>0.0462</td>\n      <td>0.0526</td>\n      <td>0.0000</td>\n      <td>0.6316</td>\n      <td>7.842105</td>\n      <td>0.4211</td>\n      <td>55.000000</td>\n      <td>76.0</td>\n      <td>32.750</td>\n      <td>2000</td>\n      <td>9.380</td>\n      <td>199</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MR-2500</td>\n      <td>2016</td>\n      <td>632.0</td>\n      <td>119.9</td>\n      <td>0.0661</td>\n      <td>0.0526</td>\n      <td>0.0526</td>\n      <td>0.7368</td>\n      <td>2.052632</td>\n      <td>0.4211</td>\n      <td>68.611111</td>\n      <td>77.0</td>\n      <td>32.375</td>\n      <td>2008</td>\n      <td>9.500</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1009</th>\n      <td>KD-0600</td>\n      <td>2005</td>\n      <td>56.0</td>\n      <td>45.1</td>\n      <td>0.0508</td>\n      <td>0.0000</td>\n      <td>0.2000</td>\n      <td>0.2000</td>\n      <td>4.200000</td>\n      <td>0.4000</td>\n      <td>61.600000</td>\n      <td>73.0</td>\n      <td>32.880</td>\n      <td>1998</td>\n      <td>8.000</td>\n      <td>207</td>\n    </tr>\n    <tr>\n      <th>1010</th>\n      <td>AW-2100</td>\n      <td>2000</td>\n      <td>53.0</td>\n      <td>31.7</td>\n      <td>0.1846</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.5000</td>\n      <td>11.250000</td>\n      <td>0.5000</td>\n      <td>49.750000</td>\n      <td>73.0</td>\n      <td>31.500</td>\n      <td>2000</td>\n      <td>9.500</td>\n      <td>285</td>\n    </tr>\n    <tr>\n      <th>1011</th>\n      <td>WG-0750</td>\n      <td>2019</td>\n      <td>52.0</td>\n      <td>33.2</td>\n      <td>0.1034</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.5000</td>\n      <td>4.500000</td>\n      <td>0.5000</td>\n      <td>66.500000</td>\n      <td>74.0</td>\n      <td>31.500</td>\n      <td>2019</td>\n      <td>9.375</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>1012</th>\n      <td>HB-0400</td>\n      <td>2002</td>\n      <td>51.0</td>\n      <td>27.2</td>\n      <td>0.0714</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.4000</td>\n      <td>8.000000</td>\n      <td>0.8000</td>\n      <td>50.200000</td>\n      <td>72.0</td>\n      <td>NaN</td>\n      <td>2002</td>\n      <td>NaN</td>\n      <td>285</td>\n    </tr>\n    <tr>\n      <th>1013</th>\n      <td>SW-2400</td>\n      <td>2000</td>\n      <td>54.0</td>\n      <td>41.2</td>\n      <td>0.1940</td>\n      <td>0.1667</td>\n      <td>0.3333</td>\n      <td>0.1667</td>\n      <td>6.833333</td>\n      <td>0.8333</td>\n      <td>60.166667</td>\n      <td>75.0</td>\n      <td>33.250</td>\n      <td>2000</td>\n      <td>10.000</td>\n      <td>183</td>\n    </tr>\n  </tbody>\n</table>\n<p>1014 rows × 16 columns</p>\n</div>",
      "text/plain": "       player  year  attempts  avg_rating  sack_rate  alt_rate  precip_rate  \\\n0     DB-3800  2011     763.0       110.6     0.0365    0.0000       0.0000   \n1     PM-0200  2013     787.0       111.7     0.0223    0.5263       0.0526   \n2     EM-0200  2011     752.0        95.1     0.0493    0.0000       0.1000   \n3     TB-2300  2011     722.0       104.8     0.0462    0.0526       0.0000   \n4     MR-2500  2016     632.0       119.9     0.0661    0.0526       0.0526   \n...       ...   ...       ...         ...        ...       ...          ...   \n1009  KD-0600  2005      56.0        45.1     0.0508    0.0000       0.2000   \n1010  AW-2100  2000      53.0        31.7     0.1846    0.0000       0.0000   \n1011  WG-0750  2019      52.0        33.2     0.1034    0.0000       0.0000   \n1012  HB-0400  2002      51.0        27.2     0.0714    0.0000       0.0000   \n1013  SW-2400  2000      54.0        41.2     0.1940    0.1667       0.3333   \n\n      turf_rate  wind_rate  away_rate       temp  height     arm  start  \\\n0        0.7222   2.333333     0.5000  68.944444    72.0  31.250   2001   \n1        0.2632   7.526316     0.4211  57.578947    77.0  31.500   1998   \n2        0.7500   7.850000     0.5500  57.550000    77.0  30.750   2004   \n3        0.6316   7.842105     0.4211  55.000000    76.0  32.750   2000   \n4        0.7368   2.052632     0.4211  68.611111    77.0  32.375   2008   \n...         ...        ...        ...        ...     ...     ...    ...   \n1009     0.2000   4.200000     0.4000  61.600000    73.0  32.880   1998   \n1010     0.5000  11.250000     0.5000  49.750000    73.0  31.500   2000   \n1011     0.5000   4.500000     0.5000  66.500000    74.0  31.500   2019   \n1012     0.4000   8.000000     0.8000  50.200000    72.0     NaN   2002   \n1013     0.1667   6.833333     0.8333  60.166667    75.0  33.250   2000   \n\n        hand  dpos  \n0     10.000    32  \n1     10.130     1  \n2      9.750     1  \n3      9.380   199  \n4      9.500     3  \n...      ...   ...  \n1009   8.000   207  \n1010   9.500   285  \n1011   9.375   100  \n1012     NaN   285  \n1013  10.000   183  \n\n[1014 rows x 16 columns]"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:,['attempts','avg_rating','sack_rate','alt_rate','precip_rate','turf_rate','wind_rate','away_rate','temp','height','arm','start','hand','dpos']].reset_index()\n",
    "df.loc[df['dpos']==0,'dpos'] = df['dpos'].max()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1014 entries, 0 to 1013\nData columns (total 16 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   player       1014 non-null   object \n 1   year         1014 non-null   int64  \n 2   attempts     1014 non-null   float64\n 3   avg_rating   1014 non-null   float64\n 4   sack_rate    1014 non-null   float64\n 5   alt_rate     1014 non-null   float64\n 6   precip_rate  1014 non-null   float64\n 7   turf_rate    1014 non-null   float64\n 8   wind_rate    1014 non-null   float64\n 9   away_rate    1014 non-null   float64\n 10  temp         1014 non-null   float64\n 11  height       1014 non-null   float64\n 12  arm          873 non-null    float64\n 13  start        1014 non-null   int64  \n 14  hand         881 non-null    float64\n 15  dpos         1014 non-null   int64  \ndtypes: float64(12), int64(3), object(1)\nmemory usage: 126.9+ KB\n"
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a season-by-season dataframe for all quarterbacks, but we may want career averages. We also drop QB's who only lasted 1 or 2 seasons or averaged less than 100 throws a season, which is very low. The averaged career statistics for these players would be less stable (essentially the opposite of the Law of Large Numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def career_averages(group):\n",
    "#     row = {}\n",
    "#     for i, col in group.iteritems():\n",
    "#         if i!='player':\n",
    "#             row[i] = [col.mean()]\n",
    "#     row['seasons'] = [group['year'].max()-group['start'].min()]\n",
    "#     row.pop('year')\n",
    "#     new_group = pd.DataFrame.from_dict(row, orient='columns')\n",
    "#     return new_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_career = df.groupby('player').apply(career_averages).reset_index(-1, drop=True)\n",
    "# df_career = df_career.loc[(df_career['seasons']>1) & (df_career['attempts']>100), :].dropna()\n",
    "# df_career.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>attempts</th>\n      <th>avg_rating</th>\n      <th>sack_rate</th>\n      <th>alt_rate</th>\n      <th>precip_rate</th>\n      <th>turf_rate</th>\n      <th>wind_rate</th>\n      <th>away_rate</th>\n      <th>temp</th>\n      <th>height</th>\n      <th>arm</th>\n      <th>hand</th>\n      <th>dpos</th>\n      <th>seasons</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>DB-3800-2011</th>\n      <td>2011</td>\n      <td>763.0</td>\n      <td>110.6</td>\n      <td>0.0365</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.7222</td>\n      <td>2.333333</td>\n      <td>0.5000</td>\n      <td>68.944444</td>\n      <td>72.0</td>\n      <td>31.250</td>\n      <td>10.00</td>\n      <td>32</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>PM-0200-2013</th>\n      <td>2013</td>\n      <td>787.0</td>\n      <td>111.7</td>\n      <td>0.0223</td>\n      <td>0.5263</td>\n      <td>0.0526</td>\n      <td>0.2632</td>\n      <td>7.526316</td>\n      <td>0.4211</td>\n      <td>57.578947</td>\n      <td>77.0</td>\n      <td>31.500</td>\n      <td>10.13</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>EM-0200-2011</th>\n      <td>2011</td>\n      <td>752.0</td>\n      <td>95.1</td>\n      <td>0.0493</td>\n      <td>0.0000</td>\n      <td>0.1000</td>\n      <td>0.7500</td>\n      <td>7.850000</td>\n      <td>0.5500</td>\n      <td>57.550000</td>\n      <td>77.0</td>\n      <td>30.750</td>\n      <td>9.75</td>\n      <td>1</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>TB-2300-2011</th>\n      <td>2011</td>\n      <td>722.0</td>\n      <td>104.8</td>\n      <td>0.0462</td>\n      <td>0.0526</td>\n      <td>0.0000</td>\n      <td>0.6316</td>\n      <td>7.842105</td>\n      <td>0.4211</td>\n      <td>55.000000</td>\n      <td>76.0</td>\n      <td>32.750</td>\n      <td>9.38</td>\n      <td>199</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>MR-2500-2016</th>\n      <td>2016</td>\n      <td>632.0</td>\n      <td>119.9</td>\n      <td>0.0661</td>\n      <td>0.0526</td>\n      <td>0.0526</td>\n      <td>0.7368</td>\n      <td>2.052632</td>\n      <td>0.4211</td>\n      <td>68.611111</td>\n      <td>77.0</td>\n      <td>32.375</td>\n      <td>9.50</td>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>TD-1400-2007</th>\n      <td>2007</td>\n      <td>219.0</td>\n      <td>55.1</td>\n      <td>0.1093</td>\n      <td>0.0000</td>\n      <td>0.0000</td>\n      <td>0.1429</td>\n      <td>5.285714</td>\n      <td>0.4286</td>\n      <td>60.000000</td>\n      <td>76.0</td>\n      <td>32.250</td>\n      <td>9.63</td>\n      <td>6</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>MM-2800-2005</th>\n      <td>2005</td>\n      <td>207.0</td>\n      <td>55.2</td>\n      <td>0.0841</td>\n      <td>0.0000</td>\n      <td>0.1111</td>\n      <td>0.2222</td>\n      <td>4.888889</td>\n      <td>0.3333</td>\n      <td>55.555556</td>\n      <td>74.0</td>\n      <td>32.000</td>\n      <td>9.75</td>\n      <td>149</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>JS-3700-2012</th>\n      <td>2012</td>\n      <td>201.0</td>\n      <td>55.4</td>\n      <td>0.0694</td>\n      <td>0.0000</td>\n      <td>0.1429</td>\n      <td>0.5714</td>\n      <td>2.857143</td>\n      <td>0.5714</td>\n      <td>64.428571</td>\n      <td>77.0</td>\n      <td>32.000</td>\n      <td>9.75</td>\n      <td>285</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>SM-2400-2007</th>\n      <td>2007</td>\n      <td>205.0</td>\n      <td>73.9</td>\n      <td>0.0463</td>\n      <td>0.0000</td>\n      <td>0.1667</td>\n      <td>0.1667</td>\n      <td>5.833333</td>\n      <td>0.6667</td>\n      <td>66.500000</td>\n      <td>74.0</td>\n      <td>32.250</td>\n      <td>10.50</td>\n      <td>3</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>JG-1850-2016</th>\n      <td>2016</td>\n      <td>205.0</td>\n      <td>63.6</td>\n      <td>0.1126</td>\n      <td>0.0000</td>\n      <td>0.1429</td>\n      <td>0.4286</td>\n      <td>3.142857</td>\n      <td>0.4286</td>\n      <td>54.333333</td>\n      <td>76.0</td>\n      <td>32.750</td>\n      <td>9.00</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>610 rows × 15 columns</p>\n</div>",
      "text/plain": "              year  attempts  avg_rating  sack_rate  alt_rate  precip_rate  \\\nDB-3800-2011  2011     763.0       110.6     0.0365    0.0000       0.0000   \nPM-0200-2013  2013     787.0       111.7     0.0223    0.5263       0.0526   \nEM-0200-2011  2011     752.0        95.1     0.0493    0.0000       0.1000   \nTB-2300-2011  2011     722.0       104.8     0.0462    0.0526       0.0000   \nMR-2500-2016  2016     632.0       119.9     0.0661    0.0526       0.0526   \n...            ...       ...         ...        ...       ...          ...   \nTD-1400-2007  2007     219.0        55.1     0.1093    0.0000       0.0000   \nMM-2800-2005  2005     207.0        55.2     0.0841    0.0000       0.1111   \nJS-3700-2012  2012     201.0        55.4     0.0694    0.0000       0.1429   \nSM-2400-2007  2007     205.0        73.9     0.0463    0.0000       0.1667   \nJG-1850-2016  2016     205.0        63.6     0.1126    0.0000       0.1429   \n\n              turf_rate  wind_rate  away_rate       temp  height     arm  \\\nDB-3800-2011     0.7222   2.333333     0.5000  68.944444    72.0  31.250   \nPM-0200-2013     0.2632   7.526316     0.4211  57.578947    77.0  31.500   \nEM-0200-2011     0.7500   7.850000     0.5500  57.550000    77.0  30.750   \nTB-2300-2011     0.6316   7.842105     0.4211  55.000000    76.0  32.750   \nMR-2500-2016     0.7368   2.052632     0.4211  68.611111    77.0  32.375   \n...                 ...        ...        ...        ...     ...     ...   \nTD-1400-2007     0.1429   5.285714     0.4286  60.000000    76.0  32.250   \nMM-2800-2005     0.2222   4.888889     0.3333  55.555556    74.0  32.000   \nJS-3700-2012     0.5714   2.857143     0.5714  64.428571    77.0  32.000   \nSM-2400-2007     0.1667   5.833333     0.6667  66.500000    74.0  32.250   \nJG-1850-2016     0.4286   3.142857     0.4286  54.333333    76.0  32.750   \n\n               hand  dpos  seasons  \nDB-3800-2011  10.00    32       11  \nPM-0200-2013  10.13     1       16  \nEM-0200-2011   9.75     1        8  \nTB-2300-2011   9.38   199       12  \nMR-2500-2016   9.50     3        9  \n...             ...   ...      ...  \nTD-1400-2007   9.63     6       14  \nMM-2800-2005   9.75   149        5  \nJS-3700-2012   9.75   285        3  \nSM-2400-2007  10.50     3       13  \nJG-1850-2016   9.00     1        1  \n\n[610 rows x 15 columns]"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = df.copy()\n",
    "df_all['seasons'] = df_all['year']-df_all['start']+1\n",
    "df_all = df_all.loc[df_all['attempts']>200, :].dropna()\n",
    "df_all = df_all.drop('start', axis=1)\n",
    "df_all.index = df_all['player']+'-'+df_all['year'].astype(str)\n",
    "df_all = df_all.drop('player', axis=1)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we dichotamise the variable of interest. For example, we may filter to only include big or small handed players. We say small hand QB's are those in the bottom 1/3rd, and large hands are the top 1/3rd.\n",
    "\n",
    "Height and arm length are postively correlated (0.45), so it's a little difficult to control for one when investigating the other. Height is of bigger interest than arm, and we suspect it is a bigger influence. However we see the drawback in not controlling for this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp = df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "on = 'warm' # the name of the dichotomous variable\n",
    "original = 'temp' # the original variable name\n",
    "\n",
    "# specifically for height study\n",
    "# df_exp.drop('arm', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big = np.percentile(df_exp[original], q=66)\n",
    "small = np.percentile(df_exp[original], q=33)\n",
    "df_exp = df_exp.loc[(df_exp[original]>=big) | (df_exp[original]<=small), :] # only extreme values\n",
    "df_exp[on] = df_exp[original]>=big\n",
    "df_exp = df_exp.drop(original, axis=1)\n",
    "print(big, small)\n",
    "df_exp[on].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarsened Exact Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in from field_goals.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the mahalanobis frontier to see how the aggregate mahalanobis distance is changing with radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.matching import mahalanobis_frontier, match_by_distance\n",
    "df_exp[on] = df_exp[on].astype(bool)\n",
    "df_mf = mahalanobis_frontier(df_exp.drop('avg_rating', axis=1), on)\n",
    "df_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='pruned controls', y='AMD', data=df_mf)\n",
    "plt.title('Mahalanobis Matching Frontier')\n",
    "plt.show()\n",
    "plt.title('Mahalanobis Matching Frontier')\n",
    "sns.lineplot(x='pruned treatments', y='AMD', data=df_mf)\n",
    "plt.show()\n",
    "plt.title('Mahalanobis Matching Frontier')\n",
    "sns.lineplot(x='radius', y='AMD', data=df_mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a reasonable radius/caliper to minimise difference in marginal distributions but also keep as many controls as possible. This is a little difficult because we're not working with very large sample sizes as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matched = match_by_distance(df_exp, on, 'avg_rating', 'mahalanobis', caliper=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.matching import covariate_dists\n",
    "covariate_dists(df_matched.drop('avg_rating', axis=1), on=on, kde=False, hist=True, n_bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform a t-test for difference of sample means. We're more interested in distribution similarity, but large difference of means can indicate problems. The p value is the probability of observing such a difference between sample means given their population means are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "for col in df_matched.drop(['avg_rating', on], axis=1).columns:\n",
    "    rvs1 = df_matched.loc[df_matched[on], col]\n",
    "    rvs2 = df_matched.loc[~df_matched[on], col]\n",
    "    _, p = ttest_ind(rvs1, rvs2, equal_var = False)\n",
    "    print(f'P(x|H0) for {col}: {round(p,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treatment = df_matched.loc[df_matched[on],:]\n",
    "df_control = df_matched.loc[~df_matched[on], :]\n",
    "print(len(df_treatment), f'{on} samples.', len(df_control), f'not {on} samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We'll use the BEST method for comparing means of the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment = df_treatment['avg_rating']\n",
    "control = df_control['avg_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1,2, sharey=True, sharex=True)\n",
    "sns.distplot(treatment, ax=axes[0])\n",
    "axes[0].set_title(f'Passer rating - {on}')\n",
    "sns.distplot(control, ax=axes[1])\n",
    "axes[1].set_title(f'Passer rating - not {on}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the relatively small sample sizes we assume our distributions are of the students-t distribution (Kruschke).\n",
    "The students-t has a mean, variance, and degree-of-freedom.\n",
    "The degree of freedom control the normality of the data (larger dof converges to normal distribution).\n",
    "\n",
    "Lets set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors on the mean\n",
    "m_mu = pd.concat([control,treatment]).mean()\n",
    "m_sd = pd.concat([control,treatment]).std()\n",
    "\n",
    "with pm.Model() as model:\n",
    "    treatment_mean = pm.Normal('treatment_mean', mu=m_mu, sd=m_sd)\n",
    "    control_mean = pm.Normal('control_mean', mu=m_mu, sd=m_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# priors on the standard deviation\n",
    "sd_low = 1\n",
    "sd_high = 30\n",
    "\n",
    "with model:\n",
    "    treatment_std = pm.Uniform('treatment_std', lower=sd_low, upper=sd_high)\n",
    "    control_std = pm.Uniform('control_std', lower=sd_low, upper=sd_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shared prior on the degree of freedom parameter\n",
    "with model:\n",
    "    v = pm.Exponential('v_minus_one', 1/29.) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pymc3 paramaterises students t with precision, rather than standard deviation (lambda = 1/sigma^2)\n",
    "with model:\n",
    "    treatment_lambda = treatment_std**-2  # deterministic\n",
    "    control_lambda = control_std**-2 # deterministic\n",
    "\n",
    "    treatment_rating = pm.StudentT(f'{on}', nu=v, mu=treatment_mean, lam=treatment_lambda, observed=treatment)\n",
    "    control_rating = pm.StudentT(f'not {on}', nu=v, mu=control_mean, lam=control_lambda, observed=control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    # our deterministic values, we could just have easily done this with the traces.\n",
    "    diff_of_means = pm.Deterministic('difference_of_means', treatment_mean - control_mean)\n",
    "    diff_of_stds = pm.Deterministic('difference_of_stds', treatment_std - control_std)\n",
    "    effect_size = pm.Deterministic('effect_size',\n",
    "                                   diff_of_means / np.sqrt((treatment_std**2 + control_std**2) / 2)) # hard to interpret but is difference scaled by pooled variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace = pm.sample(2000) # NUTS sampling for filling our posterior\n",
    "\n",
    "    # dump the trace\n",
    "    today = dt.now().strftime('%y%m%d')\n",
    "    with open(f'../results/trace_{on}_{today}.pckle', 'wb') as f:\n",
    "        pickle.dump(trace, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.plot_posterior(trace, var_names=['difference_of_means','difference_of_stds', 'effect_size'],\n",
    "                  ref_val=0,\n",
    "                  color='#87ceeb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the diagnostics show that the sampling went as suspected with no issues (Rhat ~ 1)\n",
    "from util.stats import summary\n",
    "summary_ = summary(trace)\n",
    "summary_ # error out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Relative difference in means/lift."
   ]
  }
 ]
}